\documentclass[11pt, oneside]{amsart}

\usepackage{amsmath}
\usepackage{amssymb}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}

\usepackage{color}
\usepackage{dcolumn}
\usepackage{float}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{rotating}
\usepackage{subfigure}
\usepackage{psfrag}
\usepackage{tabularx}
\usepackage[hyphens]{url}
\usepackage{wrapfig}
\usepackage{enumitem}
\usepackage{multicol}

%\setcounter{secnumdepth}{3}
%\setcounter{tocdepth}{3}


\usepackage[bookmarks, bookmarksopen, bookmarksnumbered]{hyperref}
\usepackage[all]{hypcap}
\urlstyle{rm}

\definecolor{orange}{rgb}{1.0,0.3,0.0}
\definecolor{violet}{rgb}{0.75,0,1}
\definecolor{darkgreen}{rgb}{0,0.6,0}
\definecolor{cyan}{rgb}{0.2,0.7,0.7}
\definecolor{blueish}{rgb}{0.2,0.2,0.8}

\newcommand{\todo}[1]{{\color{blue}$\blacksquare$~\textsf{[TODO: #1]}}}
\newcommand{\katznote}[1]{ {\textcolor{magenta}    { ***Dan:      #1 }}}
\newcommand{\gabnote}[1]{ {\textcolor{cyan}    { ***Gabrielle:     #1 }}}
\newcommand{\nchnote}[1]{  {\textcolor{orange}      { ***Neil: #1 }}}
\newcommand{\manishnote}[1]{  {\textcolor{violet}     { ***Manish: #1 }}}
\newcommand{\davidnote}[1]{  {\textcolor{darkgreen}      { ***David: #1 }}}
\newcommand{\note}[1]{ {\textcolor{red}    { #1 }}}

% Don't use tt font for urls
\urlstyle{rm}

% 15 characters / 2.5 cm => 100 characters / line
% Using 11 pt => 94 characters / line
\setlength{\paperwidth}{216 mm}
% 6 lines / 2.5 cm => 55 lines / page
% Using 11pt => 48 lines / pages
\setlength{\paperheight}{279 mm}
\usepackage[top=2.5cm, bottom=2.5cm, left=2.5cm, right=2.5cm]{geometry}
% You can use a baselinestretch of down to 0.9
\renewcommand{\baselinestretch}{0.96}

\sloppypar

\begin{document}

\title[]{Overview and Summary of the First Workshop on Sustainable Software for Science: Practice and Experiences (WSSSPE1)}

\author{Authors TBD}

%\author{Daniel S. Katz$^{(1)}$, Gabrielle Allen$^{(2)}$, Neil Chue Hong$^{(3)}$, \\
%Manish Parashar$^{(4)}$, and David Proctor$^{(1)}$ }
%
%
%\thanks{{}$^{(1)}$ National Science Foundation, Arlington, VA, USA}
%
%\thanks{{}$^{(2)}$ Skolkovo Institute of Science and Technology, Moscow, Russian Federation}
%
%\thanks{{}$^{(3)}$ Software Sustainability Institute, University of Edinburgh, Edinburgh, UK}
%
%\thanks{{}$^{(4)}$ Rutgers Discovery Informatics Institute, Rutgers University, New Brunswick, NJ, USA}

\begin{abstract}
This document discusses the First Workshop on Sustainable
Software for Science: Practice and Experiences (WSSSPE1).  The content
is based on the workshop itself, as recorded in a set of
collaborative notes taken during the workshop, including discussion
about the keynote presentations, three themed panels that focus on
papers accepted by the workshop, other discussion, cross-cutting
issues, use cases, and conclusions.  It joins a nascent literature
seeking to understand what drives software work in science and how the
reward systems of science thereby shapes the type of software work
undertaken, including the extent to which developers are motivated to
build software for the long-term, for the use of others, and whether
to work collaboratively or separately. Unique perspectives were
captured about issues such as documentation of APIs, software
deployment, and development practices; software licenses; career
paths for scientific software developers; identifiers for software
through a mechanism such as a Digital Object Identifier or
publication of a ``software paper''; and evidence of software
contribution and impact, recorded in online systems such as source
code repositories like GitHub. For truly sustainable software there
should be no endpoint, as the software products continue to be used
and useful beyond the single institution, grant, and developer or
development team.

\end{abstract}


\maketitle

%\note{papers and presentations and URLs should be references - see
%  figshare-web in .bib file for URL style example}

People who have volunteered to work on this report: (with * for actual
contributors - \note{if you contribute, add a * by your name})

The workshop organizers:
\begin{itemize}
\item * Daniel S. Katz $\langle$\url{dkatz@nsf.gov}$\rangle$
\item Gabrielle Allen $\langle$\url{gdallen@illinois.edu}$\rangle$
\item Neil Chue Hong $\langle$\url{N.ChueHong@software.ac.uk}$\rangle$
\item Manish Parashar $\langle$\url{parashar@rutgers.edu}$\rangle$
\item David Proctor $\langle$\url{dproctor@nsf.gov}$\rangle$
\end{itemize}


Additional volunteers:
\begin{itemize}
% \item Chris Mattmann $\langle$\url{chris.a.mattmann@jpl.nasa.gov}$\rangle$
\item * Ketan Maheshwari $\langle$\url{ketancmaheshwari@gmail.com}$\rangle$
\item Marlon Pierce $\langle$\url{marpierc@iu.edu}$\rangle$
\item * Colin Venters $\langle$\url{C.Venters@hud.ac.uk}$\rangle$
\item Suresh Marru $\langle$\url{smarru@iu.edu}$\rangle$
% \item Lynn Zentner $\langle$\url{lzentner@purdue.edu}$\rangle$
\item Anne Elster $\langle$\url{anne.elster@gmail.com}$\rangle$
\item * Shel Swenson $\langle$\url{mdswenso@usc.edu}$\rangle$
\item * Andy Ray Terrel $\langle$\url{andy.terrel@gmail.com}$\rangle$
% \item Abani Patra $\langle$\url{abani.patra@gmail.com}$\rangle$
\item * Nancy Wilkins-Diehr $\langle$\url{wilkinsn@sdsc.edu}$\rangle$
% \item James Spencer $\langle$\url{j.spencer@imperial.ac.uk}$\rangle$
\item * Frank L\"{o}ffler $\langle$\url{knarf@cct.lsu.edu}$\rangle$
\item * James Hetherington $\langle$\url{j.hetherington@ucl.ac.uk}$\rangle$
\item * Sou-Cheng (Terrya) Choi $\langle$\url{sou.cheng.terrya.choi@gmail.com}$\rangle$
\item * James Howison $\langle$\url{james@howison.name}$\rangle$
\item * Bruce Berriman $\langle$\url{gbb@ipac.caltech.edu}$\rangle$
\item * Hilmar Lapp $\langle$\url{hlapp@nescent.org}$\rangle$
\item * Marcus D. Hanwell $\langle$\url{marcus.hanwell@kitware.com}$\rangle$
\item Lucas Nussbaum $\langle$\url{lucas.nussbaum@loria.fr}$\rangle$
\item * Matthew Turk $\langle$\url{matthewturk@gmail.com}$\rangle$
\end{itemize}

The original document is
\url{https://docs.google.com/document/d/1eVfioGNlihXG_1Y8BgdCI6tXZKrybZgz5XuQHjT1oKU/edit?pli=1#}
(but can no longer be edited).  Note that the original document has
comments in addition to text.


%\pagebreak
%
%\section*{Executive Summary}
%
%\todo{1 page summary goes here}
%
%\pagebreak

\section{Introduction}

The First Workshop on Sustainable Software for Science: Practice and
Experiences (WSSSPE1,
\url{http://wssspe.researchcomputing.org.uk/WSSSPE1}) was held on
Sunday, 17 November 2013, in conjunction with the 2013 International
Conference for High Performance Computing, Networking, Storage and
Analysis (SC13, \url{http://sc13.supercomputing.org}).

Because progress in scientific research is dependent on the quality of and
accessibility to software at all levels, it is now critical to address many
challenges related to the development, deployment, and maintenance of reusable
software.
%\note{Ketan: What are the levels in scientific process where software
%is required. It might be interesting to outline these stages and types of
%software required in each stage.}
In addition, it is essential that scientists,
researchers, and students are able to learn and adopt software-related skills
and methodologies. Established researchers are already acquiring some of these
skills, and in particular a specialized class of software developers is
emerging in academic environments who are an integral and embedded part of
successful research teams. The WSSSPE workshop was intended to provide a forum
for discussion of the challenges, including both positions and experiences. The
short papers and debates have been archived to provide a basis for continued
discussion, and the workshop has fed into the collaborative writing of this
document. An estimate of 90 to 150 participants were present
throughout the day. Additional papers based on extended versions of workshop
submissions are expected. The level of interest in the workshop has led the
organizers, working with some of the submitters and attendees, to plan two
additional workshops (at the 2014 SciPy and SC14 conferences), to obtain
funds from the National Science Foundation and the Gordon and Betty Moore
Foundation to support these workshops, and to turn the
workshop website into a community website that can be used as a focus for
further discussion and progress. Additionally, a minisymposium that aims to
further explore some of the key issues raised in WSSSPE is co-organized by a
WSSSPE1 participant at the 2014 Society for Industrial and Applied Mathematics
(SIAM) Annual Meeting on ``Reliable
Computational Science.''

The goal of this paper is to summarize the contents of the workshop papers
and discussion, and identify issues that future WSSSPE events will address.
Before the WSSSPE1 workshop took place, the organizers self-published
a paper~\cite{WSSSPE1-pre-report} to document the process of
organizing and advertising the workshop, collecting and reviewing the
papers, and putting together the agenda. Section~\ref{sec:process} is
based on that publication. The remainder of this paper is based on the
workshop itself, as documented in a set of collaborative notes taken
during the workshop~\cite{WSSSPE1-google-notes}, including discussion
about the keynote presentations (\S\ref{sec:keynotes}), the three
panels (\S\ref{sec:devel}-\ref{sec:community}), 
cross-cutting issues (\S\ref{sec:cross-cutting}),
use cases (\S\ref{sec:use-cases}), and conclusions
(\S\ref{sec:conclusions}).


\section{Workshop Process and Agenda} \label{sec:process}

WSSSPE1 was organized in collaboration of the relatively small group
of five organizers and a larger peer-review committee with 36
members. This committee had early influence on the organization, e.g.,
on the specific call for papers.

The workshop call for papers included:

\begin{quote}
``In practice, scientific software activities are part of an ecosystem
where key roles are held by developers, users, and funders. All three
groups supply resources to the ecosystem, as well as requirements that
bound it. Roughly following the example of NSF's Vision and Strategy
for Software~\cite{NSF_software_vision},
the ecosystem may be viewed as having challenges related to:

\begin{itemize}[leftmargin=0.2in]
\item the development process that leads to new (versions of) software
\begin{itemize}[leftmargin=0.2in]
\item how fundamental research in computer science or
  science/engineering domains is turned into reusable software
\item software created as a by-product of research
\item impact of computer science research on the development of
    scientific software and vice versa
\end{itemize}
\item the support and maintenance of existing software, including
  software engineering
\begin{itemize}[leftmargin=0.2in]
\item governance, business, and sustainability models
\item the role of community software repositories, their operation and
  sustainability
\end{itemize}
\item the role of open source communities or industry
\item use of the software
\begin{itemize}[leftmargin=0.2in]
\item growing communities
\item reproducibility, transparency needs that may be unique to science
\end{itemize}
\item policy issues, such as
\begin{itemize}[leftmargin=0.2in]
\item measuring usage and impact
\item software credit, attribution, incentive, and reward
\item career paths for developers and institutional roles
\item issues related to multiple organizations and multiple countries,
  such as intellectual property, licensing, etc.
\item mechanisms and venues for publishing software, and the role of
  publishers
\end{itemize}
\item education and training''
\end{itemize}

\end{quote}

Based on the goal of encouraging a wide range of submissions from
those involved in software practice, ranging from initial thoughts and
partial studies to mature deployments, the organizers wanted to make
submission as easy as possible. The call for papers stated:

\begin{quote}
``We invite short (4-page) position/experience reports that will be used
to organize panel and discussion sessions. These papers will be
archived by a third-party service, and provided DOIs [Digital Object Identifiers].
We encourage
submitters to license their papers under a Creative Commons license
that encourages sharing and remixing, as we will combine ideas (with
attribution) into the outcomes of the workshop.  An interactive site
will be created to link these papers and the workshop discussion, with
options for later comments and contributions. Contributions will be
peer-reviewed for relevance and originality before the links are added
to the workshop site; contributions will also be used to determine
discussion topics and panelists. We will also plan one or more papers
to be collaboratively developed by the contributors, based on the
panels and discussions.''
\end{quote}

58 submissions were received, and almost all submitters used either
arXiv~\cite{arXiv-web} or figshare~\cite{figshare-web} to self-publish
their papers.

A peer review process followed the submissions, where
the 58 papers received 181 reviews, an average of 3.12 reviews per
paper. Reviews were completed using a Google form, which allowed
reviewers to choose papers they wanted to review, then to provide
general comments and scores on relevance to the organizers and
to the authors. The review reports enabled the organizers to decide
which papers to associate with the workshop, and allowed the authors
to improve their papers.

The organizers decided to list 54 of the papers as significant
contributions to the workshop, a very high acceptance rate but one
that is reasonable, given the goal of broad participation and the fact
that the reports were already self-published. The papers were
grouped into three main categories, namely \emph{Developing and
Supporting Software}, \emph{Policy}, and \emph{Communities}. Each
subject area was associated with a panel and discussion at the
workshop.

The workshop itself consisted of two keynote presentations and the
three panels/discussion sessions. The panels were organized based on a
classification of the workshop submissions into three categories,
following the themes of the call for papers as modified by the areas
of the submissions. Three to four representatives from each submission
category were appointed as panelists, and assigned to read a subset of
the papers in that category and then discuss them in the panel.


\section{Keynotes \note{lead: Sou-Cheng (Terrya) Choi} } \label{sec:keynotes}

The WSSSPE1 workshop began with two keynote presentations.

\subsection{A Recipe for Sustainable Software, Philip E. Bourne.} \label{sec:keynote1}

The first keynote~\cite{WSSSPE1-keynote1} was delivered by Philip
E. Bourne of University of California, San Diego.  Bourne is a basic
biomedical scientist but has also formed four software companies. He co-founded
PLOS Computational Biology~\cite{plos-web} and helped develop the RCSB
Protein Data Bank~\cite{pdb-web}.
He is working on automating three-dimensional visualizations of cell
contents and molecular structures, a problem that has not been solved
and when done, would serve as a key function of software in biomedical
sciences.

Bourne's keynote presentation was entitled ``A Recipe for Sustainable
Software,'' and developed based on his experiences.  He emphasized that
sustainability for software ``does not just mean more money from
Government'' (see also Section~\ref{sec:cross-cutting}).  Other
factors to consider, he mentioned, include costs of production, ease
of maintenance, community involvement, and distribution channels.

In places, Bourne said, development in science has improved thanks to
open source and hosting services like GitHub~\cite{github-web}, but for the most part
remains arcane. He argued that we can learn much from the App Store
model about interfaces, ratings, and so on. He also mentioned
BioJava~\cite{biojava-web} and Open Science Data Cloud~\cite{osdc-web}
as distribution channels.  On a related note, Bourne observed a common
evolutionary pathway for computational biology projects, from data
archive to analytics platform to educational use, and suggested that
use of scientific software for outreach might be the final step.

Bourne shared with the audience a few real challenges he
encountered. First, also an anecdote, he has looked into
reproducibility in computational biology, but has concluded that ``I
have proved I cannot reproduce research from my own
lab''~\cite{Veretnik}.

Another problem he experienced was staff retention with respect to
private organizations which reward those combining research and
software expertise (the ``Google Bus''). However, he is a strong fan
of software sustainability through public-private partnerships. He
noted that making a successful business from scientific software alone
is very rare: founders overvalue while customers undervalue. He noted
that to last, an open source project needs a minimal funding
requirement even with a vibrant community --- goodwill only goes so
far if one is being paid to do something else.  He talked about grant
schemes of relevance in the U.S., particularly with regard to
technology transfer~\cite{sbir-web, fased-web}.

He also had problems with selling research software: the technology
transfer office in his university wanted huge intellectual property
reach through, whereby they would get a share of profits from drugs
developed by pharmaceutical companies who use the software.  He was
aware this was unrealistic but the technology transfer office insisted
for a while. He wants to push a one-click approach for customers to
purchase university-written software.

He then presented arguments on directly valuing software as
a research output alongside papers, a common discussion within this field.
An interesting reference provided by him
is~\cite{peer-review-code}, which explores involving software
engineers in the review process of scientific code.

On the notion of \emph{digital enterprise}, where information
technology (IT) underpins the whole of organizational activities, he
contended that universities are way behind the curve. In
particular, he highlighted the separation of research, teaching, and
administration into silos without a common IT framework as a blocker
to many useful organizational innovations: ``University 2.0 is yet to
happen.'' He spoke of a circumstance where someone had used an
algorithm developed for computational biology in marketing.
The role of an institution is important in this space. He argued that
funders can help train institutions, not just individuals, in this regard.

He concluded with a reference to his paper~\cite{bourne_ten} and
argued that computational scientists ``have a responsibility to
convince their institutions, reviewers, and communities that software is
scholarship, frequently
more valuable than a research article,'' a point with which all authors
strongly agree.

\subsection{Scientific Software and the Open Collaborative Web, Arfon Smith} \label{sec:keynote2}

The second keynote~\cite{WSSSPE1-keynote2} was delivered by Arfon
Smith of GitHub.

Smith's talk started with an example from data reduction in Astronomy,
where he needed to remove interfering effects from the device. He
built a ``bad pixel mask,'' and realized that while it was persistent,
there was no way or practice of sharing this with the
data. Consequently many researchers repeated the same calculations. He
estimated that 13 person-years were wasted in this redundant
calculation.

``Why didn't we do better?''  Smith asked of this practice. He argued
this was because we were taught to focus on immediate research
outcomes and not on continuously improving and building on tools for
research. He then asked, when we do know better, why we do not act any
different. He argued that it was due to incentives and their lack:
only the immediate products of research, not the software, are valued.
He referenced Victoria Stodden's talk at
OKCon~\cite{okcon-stodden-talk} which he said argued these points
well.

C. Titus Brown~\cite{ged-web}, a WSSSPE1 contributor and participant,
argued that with regard to reusable software, ``we should just start
doing it.'' In this regard Smith replied that documentation should be
``treated as a first class entity.''  He noted that the open source
community has excellent cultures of code reuse, for example,
RubyGems~\cite{rubygems-web}, PyPI~\cite{pypi-web}, and
CPAN~\cite{cpan-web}, where there is effectively low-friction
collaboration through the use of repositories. This has not happened
in highly numerical, compiled language scientific software.  An
exception he cited as a good example of scientific projects using
GitHub is the EMCEE Markov Chain Monte Carlo project~\cite{emcee-web}
by Dan Foreman-Mackey and contributors.

He argued that GitHub's \emph{Pull Request} code review mechanism
facilitates such collaboration, by allowing one to code first, and
seek review and merge back into the trunk later.

``Open source is \ldots reproducible by necessity,'' Smith quoted
Fernando Perez~\cite{perez-open-src-reproducible}, explaining that
reproducibility is a prerequisite for remote collaboration.  He
pointed out that GitHub could propel the next stage of web
development, i.e., ``the collaborative web,'' following on from the
social web of Facebook.

In conclusion Smith reiterated the importance of establishing
incentive models for open contributions and tool builders, for
example, meaningful metrics and research grants such as~\cite{NSF_software_vision}. He urged computational scientists to
collaborate and share often their research reports, teaching
materials, code, as well as data by attaching proper licenses.

\section{Developing and Supporting Software \note{lead: Marcus Hanwell, contributors: Suresh Marru}} \label{sec:devel}

The panel on developing and supporting software examined the challenges
around scientific software development and support, mainly focused on research
groups that also produce code in various forms. There was widespread agreement
that developing and maintaining software is hard, but best practices can help.
Several participants stated that documentation is not just for users, and paying attention
to API documentation, tutorials for building and deploying software, along with
documented development practices can be very helpful in bringing  new developers
into a project efficiently.

There was discussion that backward compatibility is not always desirable, and it
can be very costly. This must be balanced with the aims of a given project, and how
many other projects depend on and use the code when backwards incompatible
changes are to be made. There are many examples in the wider open source
software world of strategies for dealing with this, and again best practices
can go a long way to mitigating issues around backwards compatibility. Many
projects live with sub-optimal code for a while, and may allow backwards
compatibility to be broken at agreed-upon development points, such as a major
release for a software library.

Communities are extremely important in software projects, and both their
building and continued engagement need attention during the project life cycle.
Several of the submitted papers discussed how communities have been built around
projects, and what is needed to enable a project to grow. Among these are public
source code hosting, mailing lists, documentation, wikis, bug trackers, software
downloads, continuous integration, software quality dashboards, and of course,
a general web presence to tie all of these things together. Questions were posed
around users not answering the questions of other users. Several participants
offered counterexamples, such as mailing lists where developers do not participate
as much due to users being more active, or whether the ``core
team'' can end up setting unrealistic expectations by doing too much. Team Geek~\cite{opac-b1134063}
and Turk's paper on scaling code in the human dimension~\cite{Turk:2013:SCH:2484762.2484782}  discuss how development
lists that are welcoming to people actually have many more people contributing.

Recruiting and/or retaining personnel in this area is hard,
with one of the major reasons being no long-term career paths (especially when
compared with industry). How should software development be balanced with
research? It is apparent that things are beginning to improve, such as
incentives for software development in the form of altmetrics, tenure committee
consideration, and NSF ``products'' vs ``publications.'' It was noted it can be very
difficult to measure where people are using small bits of your code.

There were 13 articles about different experiences in this area, but little
about GUI testing, performance, scalability, or agile development practices.
There were several unique perspectives about issues such as managing API
changes, using the same best practices for software as data, and going beyond
simply ``slapping an OSI-approved license on code.''

The question of what ``sustainable'' means in the context of software was
raised (see \S\ref{sec:cross-cutting}.) The resources at \url{http://oss-watch.ac.uk/resources/ssmm} discuss what
to look for when choosing software for procurement, or reuse in further software
development. Regardless of the license and development model that will be used,
the future of the project must be considered. Even if a particular piece of
software satisfies today's requirements, will it continue to do so in the
future? Important questions include whether the supplier will still be around in five
years time, will it still care for its customers needs, will it be responsive to
bug reports and feature requests? Should you tie your investment to a single
supplier using a proprietary product, or ensure the project uses an OSI-approved
license, and can outlive any single entity if the software is still important.

What is the overarching goal of sustainability? Is it reproducible science,
persistence, quality, something else? How should success be measured in this
context? Is there some metric that can be used to determine when you have
achieved sustainable software, or is this an ongoing process with no clear
endpoint. For truly sustainable software there should be no endpoint, as the
software products continue to be used and useful beyond the single institution,
grant, and developer/development team. Sustainability must be addressed
throughout the project life cycle.

What about actual software engineering principles, such as modularity and
extensibility? This is how industry maintains software, and ensures it continues
to be useful. Often, rewriting software is considered to be too costly, but
with a modular design it can be kept up to date. Extensibility is expected to keep
it relevant, if built into the project. One counterpoint raised by Jason Riedy
was that trying to take advantage of the latest and greatest hardware often
makes this painful, hence the lack of papers mentioning ``GPUs and exotic
hardware.''

The question of whether funders, such as the NSF, can mandate software plans in
much the same way as they do data management plans, was raised. Daniel Katz responded that
software is supposed to be described as part of the NSF data management plan,
and that in NSF's definition, data includes software. A comment from Twitter
(@biomickwatson) raised the issue that this requires reviewers and funders who
understand the answers that are given in these plans. Daniel Katz responded
that in programs focused on software or data this can be done effectively, but
agreed that in more general programs this is indeed a problem.

The papers submitted to this panel, and several others, include lots of general
recommendations for processes, practices, tools, etc. One of the papers
suggested that a ``Software Sustainability Institute'' should be vested with
the authority to develop standardized quality processes, a central common
repository, central resources for services and consulting, a think tank of
sorts, and a software orphanage center. The idea of one common repository received
some resistance, with so many compelling alternatives available, e.g. Bitbucket or
GitHub. The point for centralization of communication/point of contact was seen as
reasonable, with the statement that ``vested with authority'' is perhaps too strong,
but ``providing tools if needed'' might be more appropriate.

Some of the questions raised after the panel discussion are:

Rather than teaching developers about domain science, or domain scientists about
software development practices, why don't we teach both communities to
collaborate more effectively? Can this be done without teaching each side a
little of the other to enable communication, with a response that it really is
not two binary communities, but a spectrum with useful roles in the middle.
The question was raised if a developer can be effective without being part of the
domain community, with responses that this really depends on the specific
problem---translators and T-shaped people are important. Why aren't academic
communities taught how to evaluate cross-disciplinary work well?

What is the role for the growing field of team science? There
is overlap between the communities, with support for virtual organizations,
tool development, etc. How can we make time in an already crowded schedule to
introduce these topics to students? Should they be introduced through lab
classes as in ``real sciences''?

Are there significant differences in projects that have been running for 1, 3,
5, or 10+ years? Are there shared experiences for projects of a similar stage
of maturity? It was noted that computing and communication have changed
significantly over the past decade, and many of the experiences are tied to
the history of computing and communication. See the history of GCC, Emacs, or
the Visualization Toolkit for examples. Others felt that computing has changed
less, but communication and the widespread availability of tools has. It was
noted that email lists, websites, chat rooms, version control, virtual and
physical meetings are all over 20 years old.

There was debate that while some of the basics of computing may be fairly
similar tools commonly used for computing have changed quite
significantly. Reference was made to Perl, which was commonly used, giving way
to whole new languages, such as Python, for gluing things together and how this
induces many students into entirely rewriting the scaffolding, leaving the old
to rot and the experiments to become non-reproducible as the tools change.
Jason Riedy stated that he had been guilty of this in the past. There was
discussion of this tendency along with the enormous differences in the speed and
ease of sharing---having to ship tapes around (GCC, Emacs, etc) as opposed to
the immediate sharing of the latest development online, using revision control
systems like CVS, Subversion, Git, Mercurial, Bazaar, etc.

The question was also posed as to whether the distinction between researcher
and developer is sensible, with James Hetherington commenting that in the UK
a more nuanced view of research software engineers
and researcher developers is examined. Should this be less of a contract relationship, and
more of a collaborative relationship? This is also at the core of the business
model that Kitware presented in its submission to the workshop. Are other
ingredients missing such as applied mathematicians? Should this be defined more
in terms of skill sets rather than roles and/or identities? This builds on the
comments from Vaidy Sunderam that scientists are generally good writers, and
have mathematical skills, so why can't they learn software engineering
principles?

Miller commented that all of the infrastructure that sits around a new
algorithm that we need to make it useful and sustainable requires different
skill sets than the algorithm developer. Friere commented that there are no
good career paths for people with broad skills, no incentives for them to
continue in these roles. There was debate around people doing what interests
them, and learning computing leaves people cold, but is it that it leaves the
people who find career paths in academia cold versus the full spectrum of
people involved in research? Is this also caused by poor teaching, or because the
benefits for doing this are perceived as too small? It could also be attributed to
their focus being on science, not software engineering, or do people with
the passion for software engineering in science simply have no viable career
path and either adapt or seek out alternate career paths?


\subsection{Research or Reuse?}

Discussion of software produced as a by-product versus software
developed for reuse. How does this change the project, who develops
the code, growth beyond 1--2 person projects to larger projects with
diverse set of consumers and contributors. Modular and extensible code
versus working for current research problem---tackled by same people,
or a collaborative team?

\subsection{Defining Sustainability for Scientific Software}

What is sustainable? What are the best practices, can workshops fund
meetings to help define and improve best practices in these areas?
Software plans from the funding agencies? This topic is expanded upon
in \S\ref{sec:cross-cutting}, since it was discussed up in multiple
parts of the WSSSPE1 workshop.

\subsection{Training Scientists to Develop and Support Software}

Discussion of the evolving role of scientists, and/or others that fill
these roles.

\subsection{Software Process, Code Review, Automation, Reproducibility}

There are a lot of tools out there, but few are currently used. Look
at what some projects have found successful, and how to automate as
much as possible to reduce additional overhead.

\subsection{Software and Data Licensing}

Its impact on how and where research products are used, who can
collaborate and what patterns have worked/not worked in existing
communities.

\subsection{Funding, Sustainability Beyond the First Grant/Institution}

How initial software development is funded, moving to follow up
projects, maintenance, community growth, collaborating with other
institutions, labs, industry, internationally. Contract relationship
versus collaborative development between scientists and software
developers.

\subsection{Training Others to use Software}

Who creates training materials, how are they distributed, integration
into courses when projects see very wide application in research.

\section{Policy \note{lead: Colin Venters, contributors: James Howison, Hilmar Lapp}} \label{sec:policy}

\todo{some text is needed here before the first subsection}

\subsection{Modeling Sustainability}

Frameworks provide a scaffold for thinking; they help us understand which elements are important and how they relate. They also help us break down a problem into chunks that can be pursued by different groups or perhaps disciplines.

A group of papers submitted to the workshop provide frameworks with these intentions. The frameworks have substantial overlap but with different emphases and extents.  Accordingly we present them starting with the area of most overlap and proceed to show the different emphases and the range of factors included in the frameworks.

%\todo{seems like definitions will be mentioned elsewhere in the paper?}
Each of the framework papers included a definition of sustainability, with many overlaps.  In essence the papers related the question to change over time, an idea well captured in the definition used by the UK's Scientific Software Sustainability Institute: ``software you use today will be available---and continue to be improved and supported---in the future,'' as quoted in~\cite{Venters_WSSSPE}. This idea was also expressed as software that continues to serve its users~\cite{Pierce_WSSSPE}.
See \S\ref{sec:cross-cutting} for more on the discussion of definitions of sustainability in the workshop.

One area in which there was not complete overlap was whether the word (and thus the effort called for by the WSSSPE workshop) involved environmental sustainability. Of course the word sustainability has strong connotations from consideration of environmental issues, evoking some mention of the areas in which software interacts with overall environmental resource usage, particularly energy efficiency.  The two papers in this area which mentioned this did so without integrating that analysis into the question of software being around long-term, suggesting that questions of environmental impact of scientific software is a conceptually distinct area of inquiry.

One group of papers presented frameworks that were primarily about characteristics of software artifacts, connecting with the long discourse on software quality. This approach is realized in adjectives that can be applied to pieces of software but might also extend to describe software projects.  Thus Calero and colleagues~\cite{Calero_WSSSPE} propose adding elements to the ISO standards for measuring software quality: proposing an additional dimension of quality they call perdurability or ability to ``last over time'' made up of three characteristics: reliability, maintainability and adaptability. This shows some overlap with the framework employed by Venters et al.~\cite{Venters_WSSSPE} who employ the adjectives of ``extensibility, interoperability, maintainability, portability, reusability and scalability,'' anticipating the sorts of work that people would need to do with a software artifact in the future, ``as stakeholders requirements, technology and environments evolve and change.'' Venters et al. argue that these choices are really made very early because they relate to the architecture of the software and involve trade offs that ought to be analyzed alongside other attributes of the software artifact. Lenhardt et al~\cite{Lenhardt_WSSSPE} compare the software lifecycle to the data lifecycle to argue for the inclusion of metadata throughout a piece of software's life (discussing, for example, how it has been built and tested and what ``data in'' and ``data out'' has been considered). In addition, their analogy suggests that the software lifecycle might add a phase of ``preservation'' and draw on understandings of what that involves from studies of data.  In sum, then, these frameworks focused on what needs to be accomplished to have more sustainable software.

A second theme in these papers was the continued availability of resources to accomplish the goals of sustainability. The elements of these frameworks focused far more on the organization of a software project than they did on characteristics of the artifact itself (although it is certainly true that the adjectives discussed above could be applied to a software project). For example Pierce et al~\cite{Pierce_WSSSPE} focus on the way that the project is run, particularly in terms of how those involved communicate and jointly set priorities, a process they call governance. In particular they argue that because sustainability relates to having ongoing resources, governance must be open to receive diverse input (by occurring online, asynchronously, and publicly) and thus have the potential to ``transform passive users into active contributors''. They argue that the Apache Software Foundation's incubation process teaches this and could be learned from by projects throughout scientific software.  Katz and Proctor~\cite{Katz_WSSSPE} also discuss governance, describing two modes: ``top-down'' and ``bottom-up'' governance.  They place governance alongside questions of the artifact (``technical''), and questions of the origins of resources, in terms of who is funding the work surrounding a piece of software (``the political'') and the manner in which resources come to the project initially (commercial, open source, closed partnerships, grant funded) and long-term (all four plus paid support).

Frameworks also addressed themselves to the context in which software projects exist (thus moving upwards in abstraction, from the artifact itself, to the organization of its production and, in these frameworks, the shape of the space which an artifact or project exists in). These frameworks take the form of contingency theories in that they outline a different set of challenges and argue that different project organizations (and presumably artifact attributes) are necessary to persist longterm in spaces with particular characteristics.  Katz and Proctor~\cite{Katz_WSSSPE} propose thinking of this idea of space in terms of three axes: temporal (long or short term needs), spatial (local or global use) and purpose (specific to general).  They propose that different project organizations will be needed in different locations and argue that we should concentrate research to understand those connections. Weber et al~\cite{Weber_WSSSPE} describe their spaces by analogy with natural ecosystems as ``niches'' which sustain particular pieces of software. They define ``a software niche as the set of technical requirements, organizational conditions and cultural mores that support its maintenance and use over time.'' They call for better understanding and modeling of niches (as well as further exploration of the usefulness of ecosystem metaphors).

\subsection{Credit, Citation, Impact}

The policy panel and discussion addressed the question of recognition of work on scientific software and linked that recognition to questions of reward and thus motivation for particular kinds of work on scientific software. In short, software work in science was seen to be inadequately visible in ways that ``count'' within the reputation system underlying science. In his paper for this workshop, Katz placed software work along with other ``activities that facilitate science but are not currently rewarded or recognized''~\cite{Katz_WSSSPE}. Priem and Piwowar argued for the need to ``support all researchers in presenting meaningful impact evidence in tenure, promotion, and funding applications.''~\cite{Priem_WSSSPE}.  Kneply et al. argued that the visibility of software that supported a piece of science ``can have detrimental effects on funding, future library development, and even scientific careers.''~\cite{Knepley_WSSSPE}.

These papers, and the discussion at the workshop, join a nascent literature seeking to understand what drives software work in science and how the reward systems of science thereby shape the type of software work undertaken, including the extent to which developers are motivated to build software for the long-term, for the use of others and whether to work collaboratively or separately~\cite{howison_incentives_2013, howison_scientific_2011, bietz_synergizing_2010}. Software work is not only motivated by direct citations, but the visibility of software work in the literature is important to those who write software used in science.

Papers and discussion concentrated in three areas: How ought software work to be visible, what are the barriers to its visibility, and what can be done to make it more visible?

Most of the papers in this area focused on visibility of software in scientific papers, since scientific papers are the most widely accepted documentation of achievement in science. It was noted that there appear to be no widely accepted standards on how the use of software towards a paper ought to be mentioned, that journals, citation style guides and other guides to scientific conduct are vague about how to describe software. To address this, papers spoke of a need for a fixed identifier for software, either directly through a mechanism such as a Digital Object Identifier~\cite{Katz_WSSSPE,Knepley_WSSSPE} or via a published paper written to document the software (and perhaps its creation), a ``software paper''~\cite{Chue_Hong_WSSSPE}.

Another approach is to try to reduce the difficulty of citing software for authors, acknowledging that authors are often working with software that itself wraps other software and therefore hides that software. Knepley et al~\cite{Knepley_WSSSPE} approach this by proposing a mechanism by which the software itself, after it has run, provides the user with a set of citations that are relevant to the code actually run. They describe a prototype implementation whereby the citations are embedded in libraries and reported along with the results, via a commandline interface~\cite{Knepley_WSSSPE}. Discussion highlighted the difficulty that attempting to acknowledge the contributions of all pieces of dependent code within a paper faces the difficulty of creating very long citation lists, straining the analogy of code used to papers cited. Katz approaches this issue by proposing a system of ``transitive credit,'' recording dependencies and relative contributions outside particular papers, relieving authors from the responsibility of acknowledging each and every dependency. Instead authors would acknowledge the percentage contribution of the software they used directly and an external system would then be able to recursively allocate that credit to those who had provided dependencies. Finally Priem and Piwowar argued that machine learning techniques could examine the body of published literature and extract mentions of software, coping with the multitude of informal ways in which authors mention software they have used~\cite{Priem_WSSSPE}.  Discussion included turning the emphasis from asking users to improve their citation of software contributions, to ask how projects producing software might monitor the literature to improve their ability to show impact. Michael McLennan described the approach taken by the NanoHub project to scan the literature using keywords and names of known users to discover papers that are likely to have used their software and platform, then to have graduate students read each paper, highlighting any mention and perhaps following up with the authors to locate stories of impact.  Work since the workshop has described this process at \textit{publications.wikia.com}.

Acknowledgement in science does not come only in publications, of course. A key location for visibility might be in the grant funding process, both in bio-sketches and in grant project reporting. Some progress has been made here. Representatives of the NSF at the meeting emphasized these opportunities and encouraged participants to take advantage of them. Nonetheless, there was skepticism that peer review panels would value these contributions in the same ways as publications.

Priem and Piwowar argued for additionally looking beyond publications and drawing on evidence of contribution, and impact, recorded in other online systems, such as source code repositories like Github, both code contributions, downloads of code and dependencies as well as conversations about software (mailing lists, twitter and beyond)~\cite{Priem_WSSSPE}. They argue for providing scholars with flexible resources so that they can tell their own stories in the manner most appropriate for them and their audiences, a principle of the ``altmetrics'' approach.

\todo{convert this sketch to discussion of policy options}
\begin{verbatim}
        Opportunities for Policy interventions:
                Funding agencies
                Journals.  Success of data policies, growth of software policies.
                Promotion and Tenure. Follow lead of Science of Team Science in surveying policies at universities and other institutes.
\end{verbatim}
\todo{review PiratePad notes for other aspects of credit-giving discussed.}

\subsection{Implementing Policy}

The workshop contributions in this group were concerned with the
aspect of how implementation of best practices and other
recommendations for improving scientific software sustainability could
be promoted. Specifically, if scientific software is to become more
sustainable, corresponding policies and guidelines need to be such
that the scientific community can follow and implement them. This is
considerably more challenging that it might seem at first, because in
the reality of science today resources, both financial and personnel,
that could be devoted to implementation are very limited, and the
reward system does not encourage scientists to do so. Furthermore,
implementing sustainability-targeting policies and guidelines often
takes a variety of specialized software engineering expertises, which
are not necessarily found in a single engineer, and much less so in a
domain scientist cross-trained in programming. Adding to the policy
implementation challenges, applicable sustainability-promoting
practices and guidelines will change through a software project's
lifecycle, in particular as it gains maturity.

Two of the papers in this group focus on specific facets of software
design that are important factors in a project's sustainability but
are often addressed only late in the scientific software development
cycle, if at all: Krintz et al~\cite{Krintz_WSSSPE} look at API
governance, and Heiland et al~\cite{Heiland_WSSSPE} discuss maturity
models for software security. The other two papers discuss
implementation strategies for science from the perspective of
facilitating many or all facets of sustainanability-oriented software
design for science: Blanton and Lenhardt\cite{Blanton_WSSSPE} contrast
large projects that have software infrastructue development built-in
with cross-training domain scientist PIs in software engineering best
practices. Huang and Lapp~\cite{Huang_WSSSPE} discuss how various
specialized software engineering skills could be turned into shared
instrumentation with low barriers to access.

Krintz et al~\cite{Krintz_WSSSPE} describe how in an era in which
computing frequently takes place in a distributed cloud, the control
over digital resources is increasingly shifting from physical
infrastructure to APIs, in particular web-service APIs. Yet, as Krintz
et al observe, unlike for physical IT infrastructure in data centers,
science communities have developed very little in the way of practices and
technology for API governance, refered to by Krintz et al as the
``combined policy, implementation, and deployment control''. Web APIs
can and do change, sometimes quite frequently. raising the need to
port dependent applications. The effort required for porting is
notoriously difficult to estimate, making it nearly impossible for IT
organizations to assess and thus properly manage the impact of API
changes. To address this, Krintz et al propose a mechanism that
evaluates the porting effort between two versions of a web-service API
in a formal and automated way. To analyze the porting effort, they
divide API changes into \emph{syntactic similarity}, the changes in
inputs and outputs, and into \emph{semantic similarity}, the changes
in the API's behavior. In initial tests, their method showed good
congruence with human developers in scoring porting effort, offering
the possibility that API governance can become as solid a part of
scientific IT management as data center infrastructure management is
today.

Another aspect of sustainable software that is rarely given due
diligence in scientific software design is software security. Heiland
et al~\cite{Heiland_WSSSPE} discuss how the security measures
appropriate for scientific software strongly depend on the maturity
level of the software. However, the maturity level of a software
project meant to be sustained changes tremendously over its
development life cycle, and the eventual maturity level is often
difficult to predict during initial development. Best practice models
for identifying and defining cybersecurity vulnerabilities at
different stages of the software life cycle have been formalized as
Software Security Maturity Models. Although these are widely used in
industry, awareness among scientific software development communities
is low. Developing such models for scientific software would align
well with the objective of providing implementation approaches that
the scientific community can actually follow: A Software Security
Maturity Model provides a path to tightening security practices as
software matures, emphasizes understandability over complexity, and
classifies cybersecurity-pertinent practices for easy recognition of
what level of cybersecurity a software addresses.

% Finally, well look at some papers that discuss implementing sustainability in scientific software.

% Blanton and Lenhardt from the Renaissance Computing Institute discuss these issues from a user perspective.

% The authors focus on a point that has been brought up many times in this context:
% There is a tension between writing code that is good enough just to get it done, i.e. to publish a paper about scientific results obtained using software, 
% and getting it right, that is, developing software that is comprehensible to future users and reviewers.
% Just because the elevator panel works like this doesnt mean its sustainable for the long run.
% We dont have a way to validate that the software used in a paper is actually done right.
% The best way to get software designed correctly is to make sure best practices are considered from the start.

% The authors highlight two models for sustainable software, at different extremes:
% One is what they call co-funding:
% In these projects, usually large, multi-year collaborations, 
% there is equal emphasis on both the science and the software development. 
% Both are planned into the project from inception. 
% In the life sciences, the iPlant Collaborative, Galaxy Project, and Qiime are good examples of these sorts of large, well-designed projects.

% At the other extreme, they discuss software carpentry: 
% in this model, its assumed that the scientists themselves will write and maintain their code.
% Groups like Software Carpentry and ROpenSci assume that 
% scientists wont have access to dedicated software engineering, 
% so they try to give them tools to use best practices in their own software development.

% There might be a middle ground here: a way to get the engineering expertise that large co-funded projects have to individual scientist-developers.
% Hilmar Lapp of NESCent and I discuss one such possibility in our paper, Software Engineering as Instrumentation for the Long Tail of Scientific Software.

% What do we mean when we refer to the long tail of scientific software?
% Think of the distribution of resources in scientific software. Most are focused on big projects with lots of community buy-in and funding. But a lot of scientific software exists away from this model.
% For example, scientific software can be used long after the original developer has moved on or the funding runs out.
% Look at MacClade: it was originally released in 1986 and last updated in 2005,
% but it was still cited over 400 times in 2013!
% The scientists who developed it have a newer package, Mesquite, that was meant to replace MacClade, but they havent had sufficient time or resources to maintain either package fully, let alone both of them.

% Another dimension of the long tail can also be found in my particular research domain. 
% In the field of phylogenetics, we have a lot of programs that implement different computational methods in slightly different ways.
% Here, Joe Felsenstein has listed some (but not anywhere near all) phylogenetics packages available online.
% Most of these programs are developed by academic scientists
% They generally have limited training in software engineering
% Limited time or career incentive to improve software
% Limited funding

% So, to summarize a bit:
% Making sustainable software means we have to pay attention to many facets of software design, like APIs, security, user experience, testing, etc.
% A single project that requires one full-time software engineer may actually require fractions of different kinds of engineers. 
% But long-tail projects cant even fund one FTE, let alone one that can address all these facets.

% Then we have to consider that the users of scientific software are scientists, 
% so the developers need to understand the users and the science.
% This is the idea of a t-skilled person: 
% one who is both well-versed in a scientific domain 
% and deeply experienced in one or more facets of software engineering. 
% These people are pretty rare in the first place and difficult to retain in academia, because the academic career structure doesnt incentivize this. 

% We should look at software engineering as an expensive resource, but one that needs to be accessible to scientists at all levels.
% Think of it as analogous to DNA sequencing:
% Sequencers used to be something that individual labs and institutions had to 
% buy, maintain, and operate themselves, 
% so only highly-funded operations had them and probably didnt use them to their full capacity even when they had one.
% But now, core facilities provide the instrumentation and service to labs of any size. 
% Anyone can pay a core facility to sequence their samples for them and provide quality control and bioinformatics advice as additional services.

% We propose that software engineering can be instrumented in a similar way. 
% Lets create a nonprofit center for scientific software engineering.
% This center can hire these t-skilled personnel and provide access to them for projects at contracted cost.
% Because the center is focused on providing development services to scientific projects, it is not tied to the long-term success or failure of any individual project.
% It would emphasize the centrality of doing good science by making functional software tools as envisioned by scientists.

% So, to conclude
% Implementing policies to encourage sustainability in scientific software 
% requires that many facets of good software design are addressed throughout the lifecycle of these projects. 
% But most of them arent addressed in the status quo.
% Weve highlighted some of these facets today and suggested some possible solutions.
% Large projects can afford to hire software engineers with the expertise to implement these facets correctly.
% Grassroots developer groups can provide guidance to scientists about best practices in software development.
% We think there is a place for a software engineering center that can provide 
% both engineering expertise and guidance 
% with a contract-driven instrumentation model 
% to the scientific software in the long tail.



% note that paper summaries are available in tag jameshowison-paper-summaries: 
% https://github.com/danielskatz/WSSSPE/blob/jameshowison-paper-summaries/WSSSPE1_report/WSSSPE1_summary_report.tex



\subsection{Career Tracks for Scientific Software Developers}

How to ensure software is sustainable by ensuring there are career
paths for developers.

What are the possible career paths for a specialist software developer working as part of a scientific research group?

\section{Communities \note{lead: Matthew Turk, contributors: Nancy Wilkins-Diehr, Chris Mattmann, Suresh Marru, Frank L\"{o}ffler, Andy Terrel}} \label{sec:community}


%There were a number of papers categorized under the Communities banner and so
%two presenters each summarized half of the submissions in this area.
\todo{an intro to the whole section is needed}

\subsection{Communities}

%This collection of papers was summarized by Karen Cranston.

Drawing on experiences from high-energy physics, \cite{Vay_WSSSPE} proposed
developing teams of technical specialists able to overcome a lack of
coordination between projects.  Maximization of scientific output requires
maximizing the usability of the scientific codes while minimizing the cost of
developing and supporting those codes.  This included targeting different
architectures for their software to be deployed, as well as coordination
between technically-focused individuals and usage of a common scripting
language between projects.  Instead of fragmenting the development of
simulation codes across institutions, the paper suggests that a cohesive
strategy reducing duplication and increasing coordination will broadly increase
the efficiency across institutions.  The approach proposed is of de-fragmenting
the existing ecosystem in a non-disruptive way.

The paper by Maheshwari et al.~\cite{Maheshwari_WSSSPE} focuses on ``technology
catalysts" and their role in the modern scientific research process. A technology
catalyst can be defined as a role played by an individual with a know-how of
technological advancements, tasked with user-engagement with a goal of enacting
scientific or engineering applications, and using suitable tools and techniques
to take advantage of technological capabilities thus benefiting applications.

One of the tasks of technology catalysts is to seek community collaborations for new
applications and user engagement thus benefiting both: science, by effective
running of scientific codes on computational infrastructure, and technology,
by conducting research and seeking findings for technology improvement.
The particular engagements described in the paper came up from authors work as
postdoctoral researcher at Cornell and Argonne. Interaction with the scientific
communities in both institutions resulted in these collaborations.

In \cite{Hanwell_WSSSPE}, the authors reflect on the 15-year history of open
source software development at Kitware.  In particular, they focus on their
success at growing their community of users through enabling multiple channels
of communication, directly reaching out to individuals, and lowering the
barrier to entry for contributions. This involves providing clear,
test-oriented and review-based mechanisms for evaluating contributions,
permissive licenses, and a service-based model for sustaining development.
This model enables Kitware to review both public funding, as well as private
funding to support improvements and targeted developments of the software.

At NESCent, a combination of in-house informatics individuals and domain
scientists collaborate to develop software to study evolutionary science.  The
report~\cite{Cranston_WSSSPE} studied the success of a ``hackathon'' model
for development, where short-form, hands-on events combining users,
researcher-developers and software engineers targeted specific code
improvements. From this experiment, the authors identified several key
outcomes as well as lessons-learned -- specifically, the co-localization of
developers was seen as having a strong impact, enabling casual conversation
that led to discrete outcomes.  The formation of the discussion mailing list,
specifically in response to the social capital built at the hackathon, was seen
as spurring on longer-term benefits to the community and fostering
sustainability.

\cite{Hart_WSSSPE} addresses the success of the rOpenSci project in developing
collaborations supporting tool development for Open Science.  This software
collective, organized around the statistical programming environment R,
develops access mechanisms for data repositories and attempts to reduce the
barrier to entry for individuals wanting to access data repositories and study
the data contained therein.  The collective fosters direct collaboration
between individuals and data providers, designed to ``train academics in
reproducible science workflows focused around R.''  The two central challenges
to this goal were identified as engagement of existing users within ecology and
evolutionary biology (EEB), and how the community could make inroads and traction
in other disciplines. Currently, the collective is exploring addressing these
challenges through use of social media and holding workshops and hackathons.
This helps to both raise the profile of the collective within EEB and in other
domains.  However, the overarching challenge identified in the paper was that
of incentivizing maintenance of software, which is difficult in academia.

%\subsection{Communities Part 2}

%Nancy Wilkins-Diehr summarized 6 papers in this part.

Christopherson et al.~\cite{Christopherson_WSSSPE} outlines the degree to which research relies on high
quality software. There are often barriers and a lack of suitable incentives
for researchers to embrace software engineering principles. The Water Science
Software Institute is working to lower some of these barriers through an Open
Community Engagement Process. This is a 4-step iterative development process
that incorporates Agile development principles.

\begin{itemize}
\item Step 1: Design - thorough discussion of research questions
\item Step 2: Develop working code
\item Step 3: Refine based on new requirements
\item Step 4: Publish open source
\end{itemize}

Christopherson reports on the application of Steps 1-3 to a
computational modeling framework developed in the 1990s. Step 1 was realized as
a 2-day, in person specifications meeting and code walkthrough. Step 2 was a
5-day hackathon to develop working code, and Step 3 was a 3-day hackathon to refine
the code based on new requirements. The team worked on small, low-risk units of
code. It was challenging, revealed unanticipated obstacles, programmers had to
work together, and experimentation was encouraged.

The paper summarized recommendations to others wishing to engage in this or a
similar process, starting small and gradually building toward more complex
objectives. This is consistent with Agile development. Refactor before adding
new functionality. Approach development as a learning experience. Welcome
experimentation, and treat mistakes as a natural part of the learning process.
Repeat Step 1 activities before all hackathons to develop consensus before
coding. This allows coding to be the focus of subsequent hackathons. In higher
risk situations, provide additional time for Step 1 activities. The
Christopherson team recommends a minimum of two months. Ensure any newcomers
receive some form of orientation prior to the hackathon, such as a code
walkthrough or system documentation. Co-locate rather than collaborating
remotely whenever feasible.

Pierce et al.~\cite{Pierce2_WSSSPE} described how science gateways can provide a user-friendly
entry to complex cyberinfrastructure. The paper opens with a description of the
explosion of use of just a few gateways. Over 3.5 years, more than 7,000
biologists have run phylogenetic codes on supercomputers using the CIPRES
Science Gateway. In 1 year, over 120 scientists from 50 institutions used the
UltraScan Science Gateway, increasing the sophistication of analytical
ultracentrifugation experiments worldwide. The new Neuroscience Gateway (NSG)
registered 100+ users who used 250,000 CPU hours in only a few months.

Gateways, however, need to keep operational costs low and can often make use of
common components. Science Gateway Platform as a Service (Sci-GaP) delivers
middleware as a hosted, scalable third-party service while domain developers
focus on user interfaces and domain-specific data in the gateway. The
middleware handles things like authentication, application installation and
reliable execution and help desk support.

One key to Sci-GaP is its openness. While based on the Apache Airavata project
and the CIPRES Workbench Framework, community contributions are encouraged
because of its open source, open governance and open operations policies. The
goal is robust, sustainable infrastructure with a cycle of development that
improves reliability and prioritizes stakeholder requirements. The project is
leveraging Internet2's Net+ mechanisms for converting SciGaP and its gateways
into commodity services.

Zentner et al.~\cite{Zentner_WSSSPE} describes experiences and challenges with the large
nanoHUB.org community. The authors define community as a ``body of persons of
common and especially professional interests scattered through a larger
society.'' This makes support challenging because of the diversity of
viewpoints and needs. The group constantly examines its policies to determine
whether they are indirectly alienating part of the community or encouraging
particular types of use.

nanoHUB's 10-year history with over 260,000 users annually provides a lot of
data to analyze. 4000 resources contributed by 1000 authors. nanoHUB serves
both the research and education community and the contribution model allows
researchers to get their codes out into the community and in use in education
very rapidly. The primary software challenges are twofold - support for the
HUBzero framework and challenges related to the software contributed by the
community.

The group has learned that community contributions are maximized with a
tolerant licensing approach. HUBzero uses an LGPLv3 license so contributors can
create unique components and license as they choose. If they make changes to
source code, the original license must be maintained for redistribution. As far
as contributed resources, these must be open access, but not necessarily open
source. This allows contributors to meet the requirements of their institutions
and funding agencies. Quality is maintained via user ratings. Documentation is
encouraged and nanoHUB supplies regression test capabilities, but the user
community provides ratings, poses questions and contributes to wishlists and
citation counts - all of which incentivize code authors.

Terrel~\cite{Terrel_WSSSPE} describes support for the Python scientific community through
two major efforts - the SciPy conference and the NumFOCUS foundation. Reliance
on software in science has driven a huge demand for development, but this
development is typically done as a side effort and often in a rush to publish
without documentation and testing. While created by academics, software support
often falls to industrial institutions. SciPy brings together industry,
government, and academics to share their code and experience in an open
environment.

NumFOCUS promotes open, usable scientific software while sustaining the
community. Specific activities include educational programs, collaborative
research tools and documentation and promotion of high-level languages,
reproducible scientific research, and open-code development. Governance of the
non-profit is a loose grantor-grantee relationship with projects allowing for
monies to be placed in the groups accounts. This has raised money to hire
developers for open code development, maintain testing machines, organize the
PyData conference series, and sponsor community members to attend conferences.

Software sustainability relies on contributions from all sectors of the user
community. Together SciPy and NumFOCUS support these sectors. By maximizing
contributions growing the user base they help develop and mature Python.

L\"{o}ffler et al.~\cite{Loffler_WSSSPE} describes the Cactus project which was started in 1996 by
participants in USA Binary Black Hole Alliance Challenge. Cactus has a flesh
and thorns, core and module, model - a community-oriented framework that allows
researchers to easily work together with reusable and extendable software
elements. Modules are compiled into an executable and can remain dormant,
becoming active only when parameters and simulation data dictate. Users can
use modules written by others or can write their own modules without changing
other code. The community has grown and diversified beyond the original science
areas.

The paper points out 4 keys to sustaining the community - modular design,
growing a collaborative community, career paths and credit. In modular design,
the Cactus project went far beyond standard practices of APIs. Domain specific
languages (DSLs) allow decoupling of components - for example I/O, mesh
refinement, PAPI counters, and boundary conditions abstracted from science
code. In academia, publications are the main currency of credit. Because the
project connects code developments to science, the work is publishable and
modules are citable. Because of the open source, modular approach, programmers
can see the impact of their contributions and often continue work after
graduation. Career paths remain a challenge, however. Tasks that are essential
from a software engineering perspective are often not rewarded in academia. The
best programmers in a science environment often have multidisciplinary
expertise. That also is not rewarded in academia.

Wilkins-Diehr et al.~\cite{Wilkins-Diehr_WSSSPE} describes an NSF software institute effort to build a
community of those creating science gateways or web portals for science. These
gateways, as described in some of the other papers in this section, can be
quite capable, having a remarkable impact on some parts of science.

This paper mentioned challenges highlighted by other papers in this section -
mainly the conflict between funding for research vs infrastructure and the
challenges around getting academic credit for infrastructure. Because the
authors have studied many projects, they've also observed how development is
often done in an isolated hobbyist environment. Developers are unable to take
advantage of similar work done by others, isolation even when projects have
common needs. But often projects struggle for sustainable funding because they
provide infrastructure to conduct research and many times only the research is
funded. Gateways also may start as small group research project, taking off in
popularity once they go live without any long term plans for sustainability or
without resources in the project to plan for such. Subsequent disruptions in
service can limit effectiveness and test the limits of the research community's
trust. The impact of gateways can be increased substantially if we understand
what makes them successful.

Recommendations from an early study of successful gateways include the
following. Leadership and management teams should design governance to
represent multiple strengths and perspectives, plan for change and turnover in
the future, recruit a development team that understands both the technical and
domain-related issues, consider sustainability and measure success early and
often. Successful projects recognize the benefits and costs of hiring a team of
professionals, demonstrate credibility through stability and clarity of
purpose, leverage the work of others and plan for flexibility. Successful
projects identify an existing community and understand the communities' needs
before beginning. Projects adapt as the communities' needs evolve. For funders,
the lifecycle of technology projects must be considered. Solicitations should
be designed to reward effective planning, recognize the benefits and
limitations of both technology innovation and reuse, expect adjustments during
the production process, copy effective models from other industries and
sectors, and encourage partnerships that support gateway sustainability.

Through a business incubator type approach, the institute plans to provide a
variety of services that could be shared amongst projects. Consultation and
resources on topics such as business plan development, software engineering
practices, software licensing options, usability, security and project
management as well as a software repository and hosting service will be
available. Experts will be available for multi-month assignments to help
research teams build their own gateways, teaching them how to maintain and add
to the work after the collaboration ends. Forums, symposia and an annual
conference will connect members of the development community. A modular,
layered framework that supports community contributions and allows developers
to choose components will be delivered and finally workforce development
activities will help train the next generation for careers in this cross-
disciplinary area and build pools of institutional expertise that many projects
can leverage. Shared services and forums can dramatically reduce the cost of
building and sustaining gateways. Workforce development can encourage
technology professionals to remain in the sciences.




\subsubsection{What are communities?}

The workshop did not directly answer the question ``What are communities?'' but
instead a number of different answers were indirectly presented, through the
depiction of individuals and stakeholders in different aspects of the
scientific software lifecycle.  In broad strokes, however, scientific software
communities were generally accepted as consisting of individuals, often but not
always composed of scientist practitioners, that were working with some degree
of coordination toward a common goal enabled by software.

The discussion of development-focused communities centered around describing
methods of interaction between individuals and the scientific software.  The
first type of interaction was the development of a specific piece of software,
the second was a particular domain or discipline, and the final primary
type of interaction was around the development of applications built on a
particular piece of software that was perhaps developed by another group.  As
an example, in \cite{Hanwell_WSSSPE}, the community described is comprised of
both the for-profit company Kitware and the users and contributors to their
software packages such as VTK.  This structure, of the centralized development
of core infrastructure around which communities of individuals applying that
infrastructure and developing applications utilizing it, was similarly
reflected in \cite{Terrel_WSSSPE}, where the core scientific python ecosystem
is supported by a non-profit entity that fosters community investment in that
ecosystem.  In many ways, these two organizations (Kitware and NumFOCUS)
attempt to cross domain boundaries and provide support for both the
infrastructure and application sides of community building.

\subsubsection{Challenges of community}
include metrics for community success (e.g., more external
contributors than internal).

\subsubsection{Admirable scientific software communities}
\begin{itemize}
\item example communities
\item their (quick) origin stories.
\end{itemize}

\subsubsection{Resources for learning about software communities}
\begin{itemize}
\item academic fields studying communities (and software communities).
\item courses on online communities
\item need for software carpentry module on organizing communities?
\item \cite{howison_scientific_2011}
\item \cite{citeulike:11831265}
\item \cite{citeulike:7888211}
\item \cite{citeulike:478633}
\item \cite{opac-b1134063}
\item \cite{DBLP:conf/cscw/HowisonH11}
\item \cite{DBLP:conf/cscw/2011}
\item \cite{Trapani:2011}
\item \cite{Allsopp:2012}
\item \cite{1749-4699-6-1-015010}
\item \cite{Turk:2013:SCH:2484762.2484782}
\end{itemize}

\subsection{Industry \& Economic Models}

\todo{text about papers and discussion in this part of the workshop}

\subsection{Education \& Training}

\todo{text about papers and discussion in this part of the workshop}


%\section{Other Discussion} \label{sec:other}
%
%\note{from the misc questions/answers/observations part of the google doc?}
%
%\note{all to put notes here of stuff that doesn't fit elsewhere, if any}
%
%\todo{perhaps remove this section}


\section{Cross-cutting Issue: Defining Sustainability \note{lead: Daniel S. Katz}}  \label{sec:cross-cutting}

\note{So far this reads a lot like a collection of thoughts only, without ``red line''.}
\note{Dan: assuming the previous note is from FL, what do you propose?}
The question of what was meant by ``sustainability'' in the context of software
came up in many different parts of the workshop, specifically in the first
keynote (\S\ref{sec:keynote1}), the Developing and Maintaining Software panel,
and the Policy panel.

In the opening keynote, Philip Bourne suggested that perhaps sustainability can
be defined as the effort that happens to make the essential things continue.
This leads to having to decide what it is that we want to sustain, whether what
we want to sustain is valuable, and finally, who would care if it went away,
and how one measures how much they care.

In the Developing and Maintaining Software panel, there was some discussion on
this topic: what does sustainability mean? It was pointed out that OSS Watch
proposes a Software Sustainability Maturity Model to address the issue of how
sustainability a particular element of software is, and says that this
sustainability is important. ``When choosing software for procurement or
development reuse - regardless of the license and development model you will
use - you need to consider the future. While a software product may satisfy
today's needs, will it satisfy tomorrow's needs? Will the supplier still be
around in five years' time? Will the supplier still care for all its customers
in five years' time? Will the supplier be responsive to bug reports and feature
requests? In other words, is the software sustainable?''~\cite{OSS-ssmm-web}

Attendees suggested that a key question that the definition of sustainability
is one issue on which the community needs to agree, and that ideally, an
initial definition would be determined during the workshop, or at least some
progress would be made towards this goal.  Another topic that came up is what
the goal of sustainability is.  Perhaps it is reproducible science, or
persistence, or quality, or something else.  Similarly, some attendees want to
understand how success in sustainability is measured.  How does a group of
developers know when they have actually achieved sustainable software? This led
to a comment that sustainability should be addressed throughout the full
software life cycle.

Another topic that came up during the Developing and Maintaining Software panel
is the relationship of sustainability to other software attributes.  Attendees
asked ``what is the relationship between sustainability and provenance?'' And,
``is usability separate from sustainability or a fundamental part of it?''

In addition, the Policy panel had a large amount of discussion about defining
sustainability, as one of the subtopics in that panel was Modeling
Sustainability, and modeling requires defining what will be modeled.

In this subtopic, two papers included discussion of the definition of
sustainability.  Venters et al.~\cite{Venters_WSSSPE} mentioned that this is a
rather ambiguous concept, and that the lack of an accepted definition gets in
the way of integrating the concept into software engineering. They suggest that
sustainability is a non-functional requirement, and that the quality of
software architectures determines sustainability. They then propose that
sustainability is a consequence of a set of central quality attributes:
extensibility, interoperability, maintainability, portability, reusability, and
scalability. Finally, they develop an architecture evaluation framework based
on scenarios that help to illuminate how to measure quality or sustainability
at the architectural level.

Katz and Proctor~\cite{Katz_WSSSPE} included a set of questions that could be
used to measure software sustainability, and though these questions might
falsely lead to yes or no answers, the complete set would determine a range of
values for sustainability. These questions are:
\begin{itemize}
\item Will the software continue to provide the same functionality in the future,
      even if the environment (other parts of the infrastructure) changes?
\item Is the functionality and usability clearly explained to new users?
\item Do users have a mechanism to ask questions and to learn about the software?
\item Will the functionality be correct in the future, even if the environment changes?
\item Does it provide the functionality that existing and future users want?
\item Does it incorporate new science/theory/tools as they develop?
\end{itemize}

Lenhardt~\cite{lenhardt-wssspe1-panel} summarized the contributions of the
Modeling Sustainability papers in the panel. As shown in
Table~\ref{tab:defining-sustainability}, for each paper he discussed what
software meant, whether there was a definition of sustainability, and what the
approach was to either understand or evaluate sustainability.

\begin{table}[t]
  \begin{scriptsize}
    \begin{center}
      \caption{Summary of Modeling Sustainability papers from Policy Panel.  Adapted from~\cite{lenhardt-wssspe1-panel}.}
      \label{tab:defining-sustainability}
      \begin{tabular}{|p{2.3cm}|p{3.6cm}|p{4.4cm}|p{4.8cm}|}
                \hline
{\bf Paper/Authors}
& {\bf Software}
& {\bf Sustainability}
& {\bf Approach to Understand or Evaluate Sustainability} \\
                \hline
Calero, et al.~\cite{Calero_WSSSPE}
& General notion of software. Not explicitly defined.
& Sustainability is linked to quality.
& Add to ISO \\
                \hline
Venters, et al.~\cite{Venters_WSSSPE}
& Software as science software; increasingly complex; service-oriented computing
& Extensibility, interoperability, maintainability, portability, reusability, scalability, efficiency
& Use various architecture evaluation approaches to assess sustainability \\
                \hline
Pierce, et al.~\cite{Pierce_WSSSPE}
& Cyberinfrastructure software
& Sustainable to the extent to which there is a community to support it
& Open community governance \\
                \hline
Katz and Proctor~\cite{Katz_WSSSPE}
& E-research infrastructures (i.e. cyberinfrastructure)
& Persisting over time, meeting original needs and projected needs
& Equates models for the creation of software with sustaining software \\
                \hline
Lenhardt, et al.~\cite{Lenhardt_WSSSPE}
& Broadly defined as software supporting science
& Re-use; reproducible science
& Comparing data management life cycle to software development life cycle \\
                \hline
Weber, et al.~\cite{Weber_WSSSPE}
& Software broadly defined; a software ecosystem
& Software niches
& Ecological analysis and ecosystem \\
                \hline
     \end{tabular}
    \end{center}
  \end{scriptsize}
\end{table}


Finally, in the workshop's closing session, one of the discussion topics was
what success would look like for the set of WSSSPE activities beyond just the workshop.
One of the answers that was suggested was
having an agreed version of what we mean by sustainability.


\section{Case Studies \note{lead: Ketan Maheshwari, contributors: Andy Terrel}} \label{sec:use-cases}

% == Notes and ToDos ==
% 1. Why do we classify software cases into general purpose and special
% purpose? what is different? What are the sustainability challenges each face?
% Are they radically different? What kind of research do each category support?
% Are there separate questions to ask and answer for each category? Can we
% assume that the general purpose software has a wider scope and user community
% and challenges specific to these kinds of environments are not relavent in
% the special purpose scientific software which tend to be developed in the
% small?

% 2. What are the factors that has driven the development of these cases? How
% was the development started? What was the spark? Was there a design approach
% followed? Is the software modular/extensible? Can we identify unique and
% common factors and the reasons behind them.

% 3. Can we characterize the process itself for the selected cases:
% collaborative, seperate. 

% 4. ToDo: summarize and report on an inclusive list (might not be exhaustive)
% of all the software products discussed in the workshop. (If possible color
% code the representaion according to a scheme based on the different
% dimensions pertaining to them.)

% 5. Has one or more of the following best practices played a role in the development: 
%     a) hosted community source-code and other artefacts repository
%     b) documentation, wikis and training material
%     c) mailing lists and web-presence
%     d) development process: agile, hackathons, collaborative?
%     e) regression tests, continuous integration, quality dashboard, code review

% 6. Is there a conscious effort to deal with issues such as backward
% compatibility, ...

% 7. Career path: are the original developer(s) still around? Is most of the
% discussion around career path issues a myth after all?

% 8. Is there a software paper for this software product? Cite?

% 9. Has the project proved to be sustainable so far? Does the developers,
% managers make conscious efforts to make sure the project is sustainable? What
% determines the sustainability of the project in question: science,
% publications, usability, funding, reusability? Perhaps all factors to some
% extent? What factors are dominating? Can we send out a message to current
% scientific project to emphasize on one or more of these or other aspects?
% ====

In this section, we discuss some of the software projects as case studies to
better understand the points discussed during the workshop and described in the
previous sections. We dive deeper to find how are they affected by the
sustainability related issues in practice. Additionally, we discuss issues
surrounding people, especially the career paths of original developers and
investigate to answer the question: are the original developers are still
around?

We classify the software projects discussed in the workshop in two broad
categories. First, the \emph{utility} software, comprising of general purpose
software. Utility software is often used as enabler and/or facilitator for the
development of other tools and techniques to carry out scientific work. This
includes the software developed to efficiently utilize new research
infrastructures. Second, the \emph{scientific} software, comprising the
software that was originally developed with an aim to solve a specific
scientific problem.

% Why are we classifying software like above?
This classification is motivated by our argument that the two kinds of software
projects wildly vary in factors such as scope, purpose and usage. The
development and management of each kind is significantly different.
Consequently, the sustainability challenges faced by them differ and must be
treated separately. For instance, the challenges faced by a gateway software
development project such as \textit{CIPRES} or a visualization software product
such as \textit{VisIT} are distinct to a niche software for \textit{ab initio}
modeling and simulation such as \textit{VASP} or \textit{Quantum Espresso}.

\subsection{Utility Software}
Software developed with a potentially wider audience and general purpose usage
in mind is utility software. Utility software typically does not address
fundamental research problems for a given scientific domain. Examples are
collaborative development frameworks such as \emph{GitHub} and
\emph{Bitbucket}, distributed workflow and generic computing frameworks
such as \emph{Galaxy}, \emph{nanoHUB}, \emph{SimGrid}, \emph{Swift},
\emph{Globus} and \emph{VisTrails}, and visualization frameworks such as
\emph{VisIT}. 

% What are the sustainability challenges? What are the oppurtunities?
Development is often a high risk/reward undertaking exploring uncharted
territories and is largely influenced by (re)usability factors. Owing to
relatively large number of features, the development and prototype process is
also lengthy which poses a significant survival risk. Challenges on a class of
utility software for new architectures is well discussed
in~\cite{Ferenbaugh_WSSSPE}.

On the other hand, utility software presents oppurtunities to be usable by a
larger community making its undertaking and development an attractive pursuit.
It is generally more visible in community which in turn leads to a broader and
deeper participation. For instance, promoting collaborations across the breadth
(e.g.  different departments) and depth (e.g. stakeholders within a department)
of community, one of the key ingredient of a sustainable process. Successful
utility projects reap high rewards and have a longer usage span. Development
process becomes user-driven and self-sustaining.

One such example is the \emph{Galaxy} project. It follows agile software
development practices and implements standards such as test-driven development
and socialized bug managing practices via \emph{trello}. Galaxy
\emph{histories} and \emph{toolshed} offers easy community sharing of data and
tools further promoting a collaborative environment. The project very closely
follows the guidelines described in~\cite{Carver_WSSSPE} and many
from~\cite{Prlic_WSSSPE}. Many utility software projects are often developed
aiming better utilizing a particular, new infrastructure and architecture,
e.g., \emph{MVAPICH}, \emph{VisIT}. Similarly, to leverage the power of
emerging architectures such as accelerators, new code and libraries are
required. The experience of one such effort as described
in~\cite{Ferenbaugh_WSSSPE} which met with a limited success but nonetheless
with many invaluable lessons were learned about influential cultural and
technical aspects in sustainable software development practices.

A relatively new paradigm in utility software is the software delivered as
service over the web. With increasing popularity of cloud-based storage and
computational environments, many users are leaning towards tools used as
services. \emph{GitHub} and \emph{Bitbucket} can be argued to be
such tools, catering to collaborative development. For scientific users
\emph{Globus}-based tools are a case of service-based utility software
discussed during the workshop. The data movement and sharing services offered
by Globus can be easily used over the web by collaborating researchers.
%
%
%\note{Dan: so is the only difference here that this category is aimed at new
%systems, where utility software is not?  If so, perhaps this should be
%incorporated into that subsection, so there would just be two subsections.
%Something in the framing of this subsection doesn't feel right to me.  FL: I
%respectfully disagree the the only reason to develop frameworks is to better
%utilize (new or old) infrastructure. Another really important reason is to
%modularize development, making it much easier for an individual developer/user
%to integrate their own code. Ketan: I think in this section I wanted to bring
%up a class of software projects which are undertaken with the main aim of
%tackling new systems and architectures in mind. New infrastructures such as
%GPU, Cloud, fast IB, federal science networks, etc. were on my mind as I see
%many submissions around them in the workshop.}
%
%

\subsection{Scientific software}
Scientific software consists primarily of special-purpose software that was
purpose-built for a target use-case scenario,  fixed/frozen requirements in
mind or solving a specific problem. Software projects pertaining to specific
scientific domain tend to be in a niche and the user community tends to be
small to medium. They are mostly driven by the science and specific needs of a
research group. Specific needs such as numerical accuracy and
algorithmic optimization are some of the paramount requirements of most
scientific software.  

% What are the challenges?
Long-term sustainability of scientific software is often a significant
challenge and face radically different issues compared to utility software.
Many submissions reported that software is practically considered a `byproduct'
of the actual research. Others contended that the software was not the main
funded part of their research. A smaller codebase and fixed requirements result
in stability, ease of installation, and configurability.  Many such projects
mature and are treated as libraries to be used into larger systems such as some
of the utility software discussed in the previous section. While the software
can stay stable and require relatively low maintenance, the responsibility is
often on the shoulders of a very few developers who might not be specialists in
software development. Development tends to be linear and simplistic with a
limited scope to follow software best practices.

Some examples of such software discussed as part of the workshop are,
\emph{DUNE}, \emph{R/qtl}, \emph{Kitware}, \emph{PETSc}, \emph{MINRES-QLP},
\emph{FASTMath}.  Most of the above efforts are focused on one scientific
and/or applied mathematics domain. However, sometimes such projects grow beyond
the initial vision of developers. One such example is \emph{Kitware}, which
while being a software product specializing in the scientific process, has a
core focus of developing communities around software processes. An instance of
this process is the development of the \emph{CMake} build utility, which
started out as a building tool for \emph{ITK} but grew to become a generic
build utility for C++ projects. Similarly, \emph{PETSc} is growing towards
becoming a general purpose utility system usable for solving variety of
scientific problems.
% 

Finally, it appears that the career options of developers from different kinds
of software projects differ significantly. In order to further investigate the
much discussed issue of career paths for developers of these software, we
conducted a small survey of the use-cases discussed above with respect to the
current status of its core developers. We looked at the workshop submissions
and the original cited papers for the respective software. Where available, we
looked at the webpages and source code of the earliest versions to find the
original developers. We included projects older than 5 years and excluded
relatively new projects such as \emph{SciPy} and \emph{numFOCUS} from this
survey. we find that in a majority of scientific software more than one
original developers are still around, in some cases for more than 10 years,
(eg. \emph{R/qtl}).  Whereas, in the case of utility software projects, it
appears that at least one original developer is still around, often in a
part-time or ``benefactor" role. In other cases, it appears that the original
developers have went on to assume a larger role, with the same project.

In conclusion, we find that there are distinctions in the characteristics and
the kinds of challenges faced between utility and scientific software projects.
In terms of career paths of original developers, it appears that the career
choices for utility software developers are broader compared to the developers
of scientific software. However, it appears that in the case of scientific
software, core competencies of original developers tend to be domain science
who happen to be the coders of their software. As projects as a whole, the
small-scale, specific software have a lower risk and cost in terms of
sustaining as compared to utility software. We also find that the utility
software tend to adhere more loyally to the many best practices discussed
during the workshop. Often the sustainability of scientific software projects
is achieved by the fact that the core developer or team heavily utilizes the
software for their science, e.g.,  \emph{R/qtl, PETSc}.  Furthermore, the
development of scientific software requires more scientific skills compared
with those of utility software. This diminishes the need of specialist
programmers and practices in many cases where the bulk of development is
carried out by a domain scientist. With these inferences, we believe that
separate guidelines and/or principles for sustainability be defined and
practiced for each category of scientific software and they be given separate
treatment.

\note{Dan: I think there's some overlap
  between this and the discussion in the Developing and Support
  Software section.  Perhaps this should go in the cross-cutting
  issues section?  Let's write it down here - then we can decide if it goes elsewhere}
\note{Ketan: yes, may be this section will split and merge into other sections}

\section{Conclusions} \label{sec:conclusions}

\todo{pull the discussion together}

\todo{add some analysis of the deficiencies and difficulties that are
  present in different fields, and those that are common?}

\todo{say something about licensing - lessons, advice, etc.?}

\subsection{Top Issues}

\subsection{Recommendations or Lessons}

\note{if needed.}

\subsection{Follow up actions}

\note{or at least the discussion about them, and the current plans for
  future events.}

\note{conclusions from pre-workshop paper follows}

The WSSSPE workshop has begun an experiment in how we can
collaboratively build a workshop agenda. However, contributors also
want to get credit for their participation in the process. And the
workshop organizers want to make sure that the workshop content and
their efforts are recorded.  Ideally, there would be a service that
would be able to index the contributions to the workshop, serving the
authors, the organizers, and the larger community. But since there
isn't such a service today, the workshop organizers are writing this
initial report and making use of arXiv as a partial solution to
provide a record of the workshop.

After the workshop, one or more additional papers will be created that
will include the discussions at the workshop. These papers will likely
have many authors, and may be submitted to peer-reviewed journals.


\section*{Acknowledgments}

\todo{anyone who needs to put something in here should}

Some of the work by Katz was
supported by the National Science Foundation while working at the
Foundation; any opinion, finding, and conclusions or recommendations
expressed in this material are those of the author(s) and do not
necessarily reflect the views of the National Science Foundation.


\appendix
\section{Papers Accepted and Discussed at WSSSPE1}

\section*{Developing and Supporting Software}

\subsubsection*{Development Experiences}

\begin{itemize}

\item Mark C. Miller, Lori Diachin, Satish Balay, Lois Curfman
  McInnes, Barry Smith. Package Management Practices Essential for
  Interoperability: Lessons Learned and Strategies Developed for
  FASTMath~\cite{Miller_WSSSPE}

\item Karl W. Broman, Thirteen years of R/qtl: Just barely sustainable~\cite{Broman_WSSSPE}

\item Charles R. Ferenbaugh, Experiments in Sustainable Software
  Practices for Future Architectures~\cite{Ferenbaugh_WSSSPE}

\item Eric G Stephan, Todd O Elsethagen, Kerstin Kleese van Dam, Laura
  Riihimaki. What Comes First, the OWL or the Bean?~\cite{Stephan_WSSSPE}

\item Derek R. Gaston, John Peterson, Cody J. Permann, David Andrs,
  Andrew E. Slaughter, Jason M. Miller, Continuous Integration for
  Concurrent Computational Framework and Application Development~\cite{Gaston_WSSSPE}

\item Anshu Dubey, B. Van Straalen. Experiences from Software
  Engineering of Large Scale AMR Multiphysics Code Frameworks~\cite{Dubey_WSSSPE}

\item Markus Blatt. DUNE as an Example of Sustainable Open Source
  Scientific Software Development~\cite{Blatt_WSSSPE}

\item David Koop, Juliana Freiere, Cl\'{a}udio T. Silva, Enabling
  Reproducible Science with VisTrails~\cite{Koop_WSSSPE}

\item Sean Ahern, Eric Brugger, Brad Whitlock, Jeremy S. Meredith,
  Kathleen Biagas, Mark C. Miller, Hank Childs, VisIt: Experiences
  with Sustainable Software~\cite{Ahern_WSSSPE}

\item Sou-Cheng (Terrya) Choi. MINRES-QLP Pack and Reliable
  Reproducible Research via Staunch Scientific Software~\cite{Choi_WSSSPE}

\item Michael Crusoe, C. Titus Brown. Walking the talk: adopting and
  adapting sustainable scientific software development processes in a
  small biology lab~\cite{Crusoe_WSSSPE}

\item Dhabaleswar K. Panda, Karen Tomko, Karl Schulz, Amitava Majumdar.
The MVAPICH Project: Evolution and Sustainability of an Open Source
Production Quality MPI Library for HPC~\cite{Panda_WSSSPE}

\item Eric M. Heien, Todd L. Miller, Becky Gietzel, Louise
  H. Kellogg. Experiences with Automated Build and Test for
  Geodynamics Simulation Codes~\cite{Heien_WSSSPE}

\end{itemize}

\subsubsection*{Deployment, Support, and Maintenance of Existing Software}

\begin{itemize}

\item Henri Casanova, Arnaud Giersch, Arnaud Legrand, Martin Quinson,
  Fr\'{e}d\'{e}ric Suter. SimGrid: a Sustained Effort for the
  Versatile Simulation of Large Scale Distributed
  Systems~\cite{Casanova_WSSSPE}

\item Erik Trainer, Chalalai Chaihirunkarn, James Herbsleb. The Big
  Effects of Short-term Efforts: A Catalyst for Community Engagement
  in Scientific Software~\cite{Trainer_WSSSPE}

\item Jeremy Cohen, Chris Cantwell, Neil Chue Hong, David Moxey,
  Malcolm Illingworth, Andrew Turner, John Darlington, Spencer
  Sherwin. Simplifying the Development, Use and Sustainability of HPC
  Software~\cite{Cohen_WSSSPE}

\item Jaroslaw Slawinski, Vaidy Sunderam. Towards Semi-Automatic
  Deployment of Scientific and Engineering Applications~\cite{Slawinski_WSSSPE}

\end{itemize}

\subsubsection*{Best Practices, Challenges, and Recommendations}

\begin{itemize}

\item Andreas Prli\'{c}, James B. Procter. Ten Simple Rules for the
  Open Development of Scientific Software~\cite{Prlic_WSSSPE}

\item Anshu Dubey, S. Brandt, R. Brower, M. Giles, P. Hovland,
  D. Q. Lamb, F. Lffler, B. Norris, B. O'Shea, C. Rebbi, M. Snir,
  R. Thakur, Software Abstractions and Methodologies for HPC
  Simulation Codes on Future Architectures~\cite{Dubey2_WSSSPE}

\item Jeffrey Carver, George K. Thiruvathukal. Software Engineering
  Need Not Be Difficult~\cite{Carver_WSSSPE}

\item Craig A. Stewart, Julie Wernert, Eric A. Wernert, William
  K. Barnett, Von Welch. Initial Findings from a Study of Best
  Practices and Models for Cyberinfrastructure Software Sustainability~\cite{Stewart_WSSSPE}

\item Jed Brown, Matthew Knepley, Barry Smith. Run-time extensibility:
  anything less is unsustainable~\cite{Brown_WSSSPE}

\item Shel Swenson, Yogesh Simmhan, Viktor Prasanna, Manish Parashar,
  Jason Riedy, David Bader, Richard Vuduc. Sustainable Software
  Development for Next-Gen Sequencing (NGS) Bioinformatics on Emerging
  Platforms~\cite{Swenson_WSSSPE}

\end{itemize}

\section*{Policy}

\subsubsection*{Modeling Sustainability}

\begin{itemize}

\item Coral Calero, M. Angeles Moraga, Manuel F. Bertoa. Towards a
  Software Product Sustainability Model~\cite{Calero_WSSSPE}

\item Colin C. Venters, Lydia Lau, Michael K. Griffiths, Violeta
  Holmes, Rupert R. Ward, Jie Xu. The Blind Men and the Elephant:
  Towards a Software Sustainability Architectural Evaluation Framework~\cite{Venters_WSSSPE}

\item Marlon Pierce, Suresh Marru, Chris Mattmann. Sustainable
  Cyberinfrastructure Software Through Open Governance~\cite{Pierce_WSSSPE}

\item Daniel S. Katz, David Proctor. A Framework for Discussing
  e-Research Infrastructure Sustainability~\cite{Katz_WSSSPE}

\item Christopher Lenhardt, Stanley Ahalt, Brian Blanton, Laura
  Christopherson, Ray Idaszak. Data Management Lifecycle and Software
  Lifecycle Management in the Context of Conducting Science~\cite{Lenhardt_WSSSPE}

\item Nicholas Weber, Andrea Thomer, Michael Twidale. Niche Modeling:
  Ecological Metaphors for Sustainable Software in Science~\cite{Weber_WSSSPE}

\end{itemize}

\subsubsection*{Credit, Citation, Impact}

\begin{itemize}

\item Matthew Knepley, Jed Brown, Lois Curfman McInnes, Barry
  Smith. Accurately Citing Software and Algorithms Used in
  Publications~\cite{Knepley_WSSSPE}

\item Jason Priem, Heather Piwowar. Toward a comprehensive impact
  report for every software project~\cite{Priem_WSSSPE}

\item Daniel S. Katz. Citation and Attribution of Digital Products:
  Social and Technological Concerns~\cite{Katz2_WSSSPE}

\item Neil Chue Hong, Brian Hole, Samuel Moore. Software Papers:
  improving the reusability and sustainability of scientific software~\cite{Chue_Hong_WSSSPE}

\end{itemize}

In addition, the following paper from another area were also discussed
in this area.

\begin{itemize}

\item Frank L\"{o}ffler, Steven R. Brandt, Gabrielle Allen and Erik
  Schnetter. Cactus: Issues for Sustainable Simulation Software~\cite{Loffler_WSSSPE}

\end{itemize}

\subsubsection*{Reproducibility}

\begin{itemize}

\item Victoria Stodden, Sheila Miguez. Best Practices for
  Computational Science: Software Infrastructure and Environments for
  Reproducible and Extensible Research~\cite{Stodden_WSSSPE}

\end{itemize}

\subsubsection*{Implementing Policy}

\begin{itemize}

\item Randy Heiland, Betsy Thomas, Von Welch, Craig Jackson. Toward a
  Research Software Security Maturity Model~\cite{Heiland_WSSSPE}

\item Brian Blanton, Chris Lenhardt, A User Perspective on Sustainable
  Scientific Software~\cite{Blanton_WSSSPE}

\item Daisie Huang, Hilmar Lapp. Software Engineering as
  Instrumentation for the Long Tail of Scientific Software~\cite{Huang_WSSSPE}

\item Chandra Krintz, Hiranya Jayathilaka, Stratos
  Dimopoulos, Alexander Pucher, Rich Wolski. Developing Systems for API Governance~\cite{Krintz_WSSSPE}

\end{itemize}

\section*{Communities, Models, and Education}

\subsubsection*{Communities}

\begin{itemize}

\item Reagan Moore. Extensible Generic Data Management Software~\cite{Moore_WSSSPE}

\item Karen Cranston, Todd Vision, Brian O'Meara, Hilmar Lapp. A
  grassroots approach to software sustainability~\cite{Cranston_WSSSPE}

\item J.-L. Vay, C. G. R. Geddes, A. Koniges, A. Friedman,
  D. P. Grote, D. L. Bruhwiler. White Paper on DOE-HEP Accelerator
  Modeling Science Activities~\cite{Vay_WSSSPE}

\item Ketan Maheshwari, David Kelly, Scott J. Krieder, Justin M. Wozniak, Daniel S. Katz, Mei Zhi-Gang, Mainak Mookherjee. Reusability in Science: From Initial User Engagement to Dissemination of Results~\cite{Maheshwari_WSSSPE}

\item Edmund Hart, Carl Boettiger, Karthik Ram, Scott Chamberlain. rOpenSci -- a collaborative effort to develop R-based tools for facilitating Open Science~\cite{Hart_WSSSPE}

\item L. Christopherson, R. Idaszak, S. Ahalt. Developing Scientific Software through the Open Community Engagement Process~\cite{Christopherson_WSSSPE}

\item Marlon Pierce, Suresh Marru, Mark A. Miller, Amit Majumdar, Borries Demeler. Science Gateway Operational Sustainability: Adopting a Platform-as-a-Service Approach~\cite{Pierce2_WSSSPE}

\item Lynn Zentner, Michael Zentner, Victoria Farnsworth, Michael
  McLennan, Krishna Madhavan, and Gerhard Klimeck, nanoHUB.org:
  Experiences and Challenges in Software Sustainability for a Large
  Scientific Community~\cite{Zentner_WSSSPE}

\item Andy Terrel. Sustaining the Python Scientific Software Community~\cite{Terrel_WSSSPE}

\item Frank L\"{o}ffler, Steven R. Brandt, Gabrielle Allen and Erik
  Schnetter. Cactus: Issues for Sustainable Simulation Software~\cite{Loffler_WSSSPE}

\item Nancy Wilkins-Diehr, Katherine Lawrence, Linda Hayden, Marlon Pierce, Suresh Marru, Michael McLennan, Michael Zentner, Rion Dooley, Dan Stanzione. Science Gateways and the Importance of Sustainability~\cite{Wilkins-Diehr_WSSSPE}

\end{itemize}

In addition, the following paper from another area was also discussed
in this area.

\begin{itemize}

\item Marcus Hanwell, Amitha Perera, Wes Turner, Patrick O'Leary,
  Katie Osterdahl, Bill Hoffman, Will Schroeder. Sustainable Software
  Ecosystems for Open Science~\cite{Hanwell_WSSSPE}

\end{itemize}

\subsubsection*{Industry \& Economic Models}

\begin{itemize}

\item Anne C. Elster. Software for Science: Some Personal Reflections~\cite{Elster_WSSSPE}

\item Ian Foster, Vas Vasiliadis, Steven Tuecke. Software as a Service
  as a path to software sustainability~\cite{Foster_WSSSPE}

\item Marcus Hanwell, Amitha Perera, Wes Turner, Patrick O'Leary,
  Katie Osterdahl, Bill Hoffman, Will Schroeder. Sustainable Software
  Ecosystems for Open Science~\cite{Hanwell_WSSSPE}

\end{itemize}

In addition, the following papers from other areas were also discussed
in this area.

\begin{itemize}

\item Brian Blanton, Chris Lenhardt, A User Perspective on Sustainable
  Scientific Software~\cite{Blanton_WSSSPE}

\item Markus Blatt. DUNE as an Example of Sustainable Open Source
  Scientific Software Development~\cite{Blatt_WSSSPE}

\item Dhabaleswar K. Panda, Karen Tomko, Karl Schulz, Amitava
  Majumdar. The MVAPICH Project: Evolution and Sustainability of an
  Open Source Production Quality MPI Library for HPC~\cite{Panda_WSSSPE}

\item Andy Terrel. Sustaining the Python Scientific Software Community~\cite{Terrel_WSSSPE}

\end{itemize}

\subsubsection*{Education \& Training}

\begin{itemize}

\item Ivan Girotto, Axel Kohlmeyer, David Grellscheid, Shawn
  T. Brown. Advanced Techniques for Scientific Programming and
  Collaborative Development of Open Source Software Packages at the
  International Centre for Theoretical Physics (ICTP)~\cite{Girotto_WSSSPE}

\item Thomas Crawford. On the Development of Sustainable Software for
  Computational Chemistry~\cite{Crawford_WSSSPE}

\end{itemize}

In addition, the following papers from other areas were also discussed
in this area.

\begin{itemize}

\item Charles R. Ferenbaugh, Experiments in Sustainable Software
  Practices for Future Architectures~\cite{Ferenbaugh_WSSSPE}

\item David Koop, Juliana Freiere, Cl\'{a}udio T. Silva, Enabling
  Reproducible Science with VisTrails~\cite{Koop_WSSSPE}

\item Sean Ahern, Eric Brugger, Brad Whitlock, Jeremy S. Meredith,
  Kathleen Biagas, Mark C. Miller, Hank Childs, VisIt: Experiences
  with Sustainable Software~\cite{Ahern_WSSSPE}

\item Sou-Cheng (Terrya) Choi. MINRES-QLP Pack and Reliable
  Reproducible Research via Staunch Scientific Software~\cite{Choi_WSSSPE}

\item Frank L\"{o}ffler, Steven R. Brandt, Gabrielle Allen and Erik
  Schnetter. Cactus: Issues for Sustainable Simulation Software~\cite{Loffler_WSSSPE}

\item Erik Trainer, Chalalai Chaihirunkarn, James Herbsleb. The Big
  Effects of Short-term Efforts: A Catalyst for Community Engagement
  in Scientific Software~\cite{Trainer_WSSSPE}

\end{itemize}




\section{Attendees \note{lead: Shel Swenson}}


The following is a partial list of attendees who were recorded on the
Google doc~\cite{WSSSPE1-google-notes} that was being used for live note taking at the workshop, or by the SC13 student volunteers, with some additions also made by the authors of this report.


\begin{multicols}{3}
\setlength{\parindent}{0pt}
%in theory, should save the old value then set it back after this section, but since this is the end...

Jay Alameda

Gabrielle Allen

David Andrs

Brian Austin

Lorena A. Barba

David Bernholdt

Phil Bourne

Karl Broman

Sharon Broude Geva

Jed Brown

Maxine Brown

David Bruhwiler

Bruno Bzeznik

Alexandru Calotoiu

Jeffrey Carver

Shreyas Cholia

Peng Huat Chua

Neil Chue Hong %surname is Chue Hong, this is the correct order.

John W. Cobb

Timothy Cockerill

Karen Cranston

Rion Dooley

Anshu Dubey

Marat Dukhan

Ian Foster

Juliana Freire

Jeffrey Frey

Derek Gaston

Allison Gehrke

Brian Glendenning

Christian Godenschwager

Derek Groen

Edmund Hart

Magne Haveraaen

Steven Heaton

Oscar Hernandez

James Hetherington

Simon Hettrick

Jonathan Hicks

Kenneth Hoste

James Howison

Daisie Huang

Shao-Ching Huang

Tsutomu Ikegami

Kaxuya Ishimura

Christian Iwainsky

Craig Jackson

Wesley Jones

Randall Judd

Shusuke Kasamatsu

Daniel S. Katz

Kerk Kee

Kellie Kercher

Mads Kristensen

Carolyn Lauzon

Arnaud Legrand

Chris Lenhardt

Michael Levy

Frank L\"{o}ffler

Monica L\"{u}cke

Simon A. F. Lund

Arthur Maccabe

Paul Madden

Louis Maddox

Philip Maechling

Ketan Maheshwari

Brian Marker

Suresh Marru

Cezary Mazurek

James McClure

Matt McKenzie

Chris Mentzel

Paul Messina

Mike Mikailov

J. Yates Monteith

Reagan More

Rafael Morizawa

Pierre Neyron

Lucas Nussbaum

Patrick O'Leary

Manish Parashar

Cody Permann

Jack Perdue

John Peterson

Quan Pham

Marlon Pierce

Heather Piwowar

David Proctor

Sara Rambacher

Nicolas Renon

Jason Riedy

Todd Rimer

Bill Sacks

Andreas Schreiber

William Scullin

Andrew Slaughter

Jaraslaw Slawinski

Arfon Smith

Spencer Smith

James Spencer

Eric Stahlberg

Timothy Stitt

Hyoshin Sung

Fr\'{e}d\'{e}ric Suter

Shel Swenson

Yoshio Tanaka

Andy Terrel

George  Thiruvathukal

Keren Tomko

John Towns

Erik Trainer

Satori Tsuzuki

Matthew Turk

Eric van Wyk

Colin C. Venters

Brice Videau

Tajendra Vir Singh

Von Welch

Nancy Wilkins-Diehr

Theresa Windus

Felix Wolf

Rich Wolski

Lynn Zentner

\end{multicols}


\bibliographystyle{vancouver}

\bibliography{wssspe_paper}
\end{document}
